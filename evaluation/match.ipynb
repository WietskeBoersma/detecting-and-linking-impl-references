{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "372f9769",
   "metadata": {},
   "source": [
    "# Match and analyse both annotated datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8becd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d328484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250, 15) (256, 15)\n"
     ]
    }
   ],
   "source": [
    "# Read both annotators' references\n",
    "from re import split\n",
    "\n",
    "\n",
    "df_a = pd.read_csv('annotator-a.csv')\n",
    "df_b = pd.read_csv('annotator-b.csv')\n",
    "\n",
    "# Clean the text, sentence, and identifier columns\n",
    "def clean(df):\n",
    "    df['text'] = df['text'].apply(lambda x: x.strip().replace('\\n', ' ').replace('\\r', ' ')  if isinstance(x, str) else x)\n",
    "    df['text'] = df['text'].apply(lambda x: ' '.join(x.split()) if isinstance(x, str) else x)\n",
    "    df['sentence'] = df['sentence'].apply(lambda x: x.strip().replace('\\n', ' ').replace('\\r', ' ') if  isinstance(x, str) else x)\n",
    "    df['sentence'] = df['sentence'].apply(lambda x: ' '.join(x.split()) if isinstance(x, str) else x)\n",
    "    df['external_identifier'] = df['external_identifier'].apply(lambda x: x.strip().replace('https://zoek.officielebekendmakingen.nl/', '').replace('kst-', '') if isinstance(x, str) else x)\n",
    "\n",
    "    return df\n",
    "\n",
    "df_a = clean(df_a)\n",
    "df_b = clean(df_b)\n",
    "\n",
    "print(df_a.shape, df_b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd42bf68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def panoptic_overlap_match(text1, text2):\n",
    "    \"\"\"\n",
    "    Returns True if the overlap between text1 ad text2 satsifes:\n",
    "    |A ∩ B| > 0.5|A| and |A ∩ B| > 0.5|B|\n",
    "    \"\"\"\n",
    "    set1 = set(word_tokenize(text1))\n",
    "    set2 = set(word_tokenize(text2))\n",
    "    if not set1 or not set2:\n",
    "        return False\n",
    "    intersection = set1 & set2\n",
    "    return len(intersection) > 0.5 * len(set1) and len(intersection) > 0.5 * len(set2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f8cd8c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched pairs saved to matched_pairs.csv with 191 entries.\n"
     ]
    }
   ],
   "source": [
    "matched_pairs = pd.DataFrame(columns=['minute_id', \n",
    "                                      'reference_type_a', 'document_type_a', 'text_a', 'sentence_a', 'identifier_a', \n",
    "                                      'reference_type_b', 'document_type_b', 'text_b', 'sentence_b', 'identifier_b',\n",
    "                                    ])\n",
    "\n",
    "df_a_by_minute =  df_a.groupby('minute_id')\n",
    "for _, anno_b in df_b.iterrows():\n",
    "    minute_id = anno_b['minute_id']\n",
    "    df_a_by_minute_group = df_a_by_minute.get_group(minute_id)\n",
    "\n",
    "\n",
    "    best_match = None\n",
    "    for _, anno_a in df_a_by_minute_group.iterrows():\n",
    "        # If any sentence is nan, we skip it\n",
    "        if pd.isna(anno_a['sentence']) or  pd.isna(anno_b['sentence']):\n",
    "            continue\n",
    "\n",
    "        # remove any newlines or extra spaces in sentences\n",
    "        anno_a['sentence'] = anno_a['sentence'].replace('\\n', '').strip()\n",
    "        anno_b['sentence'] = anno_b['sentence'].replace('\\n', '').strip()\n",
    "        anno_a['text'] = anno_a['text'].replace('\\n', '').strip()\n",
    "        anno_b['text'] = anno_b['text'].replace('\\n', '').strip()\n",
    "\n",
    "        sentence_match = panoptic_overlap_match(anno_a['sentence'], anno_b['sentence'])\n",
    "        text_match = panoptic_overlap_match(anno_a['text'], anno_b['text'])\n",
    "\n",
    "        # If there is a match, we add it to the matched pairs\n",
    "        if sentence_match and text_match:\n",
    "            matched_pairs.loc[len(matched_pairs)] = [\n",
    "                minute_id,\n",
    "                anno_a['reference_type'], anno_a['document_type'], anno_a['text'], anno_a['sentence'], anno_a['external_identifier'],\n",
    "                anno_b['reference_type'], anno_b['document_type'], anno_b['text'], anno_b['sentence'], anno_b['external_identifier']\n",
    "            ]\n",
    "            break\n",
    "\n",
    "# Save the matched pairs to a CSV file\n",
    "matched_pairs.to_csv('matched_pairs.csv', index=False)\n",
    "print(f'Matched pairs saved to matched_pairs.csv with {matched_pairs.shape[0]} entries.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "164701df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohen's Kappa for document_type: 0.8894\n",
      "Cohen's Kappa for reference_type: 0.8717\n",
      "Cohen's Kappa for identifier: 0.5863\n"
     ]
    }
   ],
   "source": [
    "# Calculate Cohen's Kappa for document_type and reference_type\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "kappa_document_type = cohen_kappa_score(matched_pairs['document_type_a'].tolist(),  matched_pairs['document_type_b'].tolist())\n",
    "kappa_reference_type = cohen_kappa_score(matched_pairs['reference_type_a'].tolist(), matched_pairs['reference_type_b'].tolist())\n",
    "kappa_identifier = cohen_kappa_score(matched_pairs['identifier_a'].tolist(), matched_pairs['identifier_b'].tolist())\n",
    "print(f\"Cohen's Kappa for document_type: {kappa_document_type:.4f}\")\n",
    "print(f\"Cohen's Kappa for reference_type: {kappa_reference_type:.4f}\")\n",
    "print(f\"Cohen's Kappa for identifier: {kappa_identifier:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09bc149",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
